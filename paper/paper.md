---
title: 'SplatSnap: A Python CLI Tool for Extracting Thumbnails from Gaussian Splatting Objects'
tags:
  - python
  - 3D graphics
  - Gaussian splatting
  - rendering
authors:
 - name: Evgeni Genchev
   orcid: 0009-0004-2538-8344
   affiliation: "1, 2"
 - name: Dimitar Rangelov
   orcid: 0009-0005-8511-1555
   affiliation: "2, 3"
affiliations:
 - name: Saxion University of Applied Sciences
   index: 1
 - name: Technologies for Criminal Investigations
   index: 2
 - name: University of Twente
   index: 3
date: 2025-05-06
bibliography: paper.bib
---

# Summary

SplatSnap is an open-source Python command-line tool for rapidly converting 3D *Gaussian splatting* data into 2D image thumbnails. In Gaussian splatting, a 3D scene or object is represented as a set of elliptical Gaussian “splats” (points with position, size, orientation, and color) rather than traditional mesh geometry. SplatSnap makes it easy for data scientists and machine learning researchers to generate large numbers of 2D images from such 3D representations, for example to create training datasets for object detection. Given a 3D Gaussian splatted model, SplatSnap efficiently captures its appearance from arbitrary camera angles and produces standard image files. This capability bridges advanced 3D reconstruction techniques with conventional 2D computer vision pipelines, enabling users to leverage 3D Gaussian splatting outputs in tasks like training neural networks for object recognition.



Unlike traditional rendering engines, SplatSnap is optimized for speed and simplicity over photorealism. Notably, it ignores the rotation of each Gaussian splat and treats all splats as isotropic (spherical) blobs. By assuming each splat is a sphere, the rendering computation is greatly simplified. This design choice eliminates the need to account for each splat’s orientation, which in turn allows the entire rendering process to run efficiently on a CPU only, without any specialized graphics hardware. The trade-off is a minor loss in visual detail e.g high-frequency or anisotropic details are blurred since all splats are rendered radially symmetric. However, this reduction in fidelity is acceptable for machine learning applications: convolutional models (e.g. ResNet or YOLO) typically downsample and abstract input images, so slight blurring or loss of fine detail does not impede their training. In practice, the thumbnails generated by SplatSnap retain the essential structure and features of the original 3D object needed for recognition tasks, while sacrificing only the superfluous details. Another key feature of SplatSnap is its hardware portability. Because it does not rely on GPU computing, the tool can run on modest systems and even low-power devices like the Raspberry Pi. Thus making it useful in fieldwork, mobile robotics platforms, or other constrained environments where high-end GPUs are unavailable.



# Statement of Need

It is a common requirement in computer vision and machine learning to create training images from 3D data. State-of-the-art object detection models do in fact have large and varied collections of annotated images, and one possible way of obtaining them is by synthetically rendering images from 3D simulations or reconstructions. It is a common requirement in computer vision and machine learning to create training images from 3D data. State-of-the-art object detectors are usually assisted by large quantities of diverse labeled data, and one means of obtaining such data is by rendering synthetic images from simulations or 3D reconstructions. *Gaussian splatting* is a novel 3D representation technique that has been gaining popularity for being capable of extremely fast rendering of new views of a scene on modern GPUs (e.g., operating in real-time in recent work). In this method, scenes are described in terms of sets of 3D Gaussian primitives instead of meshes, allowing for quick visualization and manipulation. However, whereas Gaussian splatting for rendering has persisted in advancing, a gap has remained in tools for taking advantage of this data in machine learning workflows.Researchers or practitioners who obtain 3D models in the form of Gaussian splats have limited options to convert them into 2D images for tasks like training an object detection algorithm. Existing 3D rendering pipelines tend to prioritize visual fidelity and typically require powerful graphics hardware or complex software setups (for instance, the original Gaussian Splatting implementations focus on GPU-accelerated, high-quality rendering). This poses a barrier for those who want to use Gaussian splat data to generate many images quickly, or to do so on ordinary hardware without GPUs.

SplatSnap addresses this need by providing a simple, high-performance tool to extract 2D thumbnails from 3D Gaussian splatting data on any standard computing platform. The target audience includes data scientists, computer vision researchers, and developers who work with 3D vision but need 2D outputs for algorithm development. In particular, those creating training datasets for object detection or related image recognition tasks. For example, a robotics researcher might reconstruct an environment using Gaussian splatting (due to its compactness and fast rendering) and then use SplatSnap to generate training images for a detection model that will be deployed on a robot. Without SplatSnap, this workflow would require either writing custom rendering code or converting the splats into a different format (like meshes or point clouds) to use in general rendering software, which can be inefficient and cumbersome. The open-source availability and Python-based CLI design of SplatSnap lower the entry barrier: users can integrate it into scripts and data pipelines with minimal effort, and run it on diverse systems ranging from powerful servers to laptops and embedded boards.

In the context of related work, SplatSnap is unique in its focus on CPU-only Gaussian splatting rendering for data generation. Other rendering solutions (such as game engines or 3D frameworks like Blender and Unity) either do not natively support Gaussian splats or require GPU acceleration for acceptable performance. By contrast, SplatSnap’s approach of simplifying splat geometry (ignoring orientation and treating splats as spheres) enables a dramatic boost in speed on the CPU. This was a deliberate design choice to meet the needs of training data generation, where producing a high volume of images is often more important than maximizing each image’s realism. In fact, the trade-off between speed and quality is a known consideration in novel view synthesis research[, and SplatSnap leans towards speed given its intended use-case. The result is a tool that can generate images in seconds even on low-end hardware, which is crucial for interactive dataset crafting or deployment in the field. This capability opens up new possibilities for using advanced 3D reconstruction outputs in places previously impractical. For instance, forensic investigators working in remote locations can capture a 3D scene with Gaussian splats and quickly produce 2D snapshots on-site for immediate analysis, all without specialized equipment.

In summary, the purpose of SplatSnap is to fill a practical gap in the software ecosystem for 3D vision: it empowers users to transform 3D Gaussian splatting data into 2D training-ready images easily and efficiently. We believe this contribution is beneficial for the research community because it connects a state-of-the-art 3D representation with the everyday needs of machine learning model development. By enabling CPU-only rendering with sufficient fidelity, SplatSnap ensures that cutting-edge 3D data (like Gaussian splats) can be harnessed even in resource-constrained settings. No existing open-source tool offers this combination of features for Gaussian splatting data. The release of SplatSnap thus provides a valuable resource for anyone looking to generate synthetic datasets from 3D reconstructions, democratizing the creation of training data and supporting experimentation in object detection, 3D scene understanding, and beyond.Gaussian splatting is an emerging 3D representation technique that has gained attention for its ability to render novel views of a scene very quickly on modern GPUs (e.g., achieving real-time framerates in recent research). In this method, scenes are stored as collections of 3D Gaussian primitives instead of meshes, enabling efficient visualization and manipulation. However, despite the advances in Gaussian splatting for rendering, there has been a gap in tools for leveraging this data in machine learning workflows. Researchers or practitioners who obtain 3D models in the form of Gaussian splats have limited options to convert them into 2D images for tasks like training an object detection algorithm. Existing 3D rendering pipelines tend to prioritize visual fidelity and typically require powerful graphics hardware or complex software setups (for instance, the original Gaussian Splatting implementations focus on GPU-accelerated, high-quality rendering). This poses a barrier for those who want to use Gaussian splat data to generate many images quickly, or to do so on ordinary hardware without GPUs.



SplatSnap addresses this need by providing a simple, high-performance tool to extract 2D thumbnails from 3D Gaussian splatting data on any standard computing platform. The target audience includes data scientists, computer vision researchers, and developers who work with 3D vision but need 2D outputs for algorithm development. In particular, those creating training datasets for object detection or related image recognition tasks. For example, a robotics researcher might reconstruct an environment using Gaussian splatting (due to its compactness and fast rendering) and then use SplatSnap to generate training images for a detection model that will be deployed on a robot. Without SplatSnap, this workflow would require either writing custom rendering code or converting the splats into a different format (like meshes or point clouds) to use in general rendering software, which can be inefficient and cumbersome. The open-source availability and Python-based CLI design of SplatSnap lower the entry barrier: users can integrate it into scripts and data pipelines with minimal effort, and run it on diverse systems ranging from powerful servers to laptops and embedded boards.



In the context of related work, SplatSnap is unique in its focus on CPU-only Gaussian splatting rendering for data generation. Other rendering solutions (such as game engines or 3D frameworks like Blender and Unity) either do not natively support Gaussian splats or require GPU acceleration for acceptable performance. By contrast, SplatSnap’s approach of simplifying splat geometry (ignoring orientation and treating splats as spheres) enables a dramatic boost in speed on the CPU. This was a deliberate design choice to meet the needs of training data generation, where producing a high volume of images is often more important than maximizing each image’s realism. In fact, the trade-off between speed and quality is a known consideration in novel view synthesis research[, and SplatSnap leans towards speed given its intended use-case. The result is a tool that can generate images in seconds even on low-end hardware, which is crucial for interactive dataset crafting or deployment in the field. This capability opens up new possibilities for using advanced 3D reconstruction outputs in places previously impractical. For instance, forensic investigators working in remote locations can capture a 3D scene with Gaussian splats and quickly produce 2D snapshots on-site for immediate analysis, all without specialized equipment.

In summary, the purpose of SplatSnap is to fill a practical gap in the software ecosystem for 3D vision: it empowers users to transform 3D Gaussian splatting data into 2D training-ready images easily and efficiently. We believe this contribution is beneficial for the research community because it connects a state-of-the-art 3D representation with the everyday needs of machine learning model development. By enabling CPU-only rendering with sufficient fidelity, SplatSnap ensures that cutting-edge 3D data (like Gaussian splats) can be harnessed even in resource-constrained settings. No existing open-source tool offers this combination of features for Gaussian splatting data. The release of SplatSnap thus provides a valuable resource for anyone looking to generate synthetic datasets from 3D reconstructions, democratizing the creation of training data and supporting experimentation in object detection, 3D scene understanding, and beyond.

# Acknowledgements

This project was developed as part of the research work carried out at the Technologies for Criminal Investigations group at Saxion University of Applied Sciences.

# References

A full list of citations is provided in the accompanying `paper.bib`.
